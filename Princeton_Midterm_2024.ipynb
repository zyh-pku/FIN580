{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Princeton University FIN 580 Midterm 2024\n",
    "## FIN 580: Quantitative Data Analysis in Finance\n",
    "## Due: 11:59 pm on Mar 18, 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup codes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.cluster import KMeans,SpectralClustering,DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "_DATA_DIR = './Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macroeconomics Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you're given access to a monthly macroeconomic dataset that covers a broad spectrum of indicators, providing a thorough insight into the U.S. economy. This dataset is regularly updated on a monthly basis. For your convenience, we have prepared a cleaned version of this dataset for analysis. The pre-processing involves de-trend and de-seasonality that you no longer need worry about. Your objective is to create a model designed to forecast Industrial Production (IP) growth. In the dataset provided, 'Y' represents the IP growth rate. Your primary focus should be on developing and suggesting a model that can accurately predict future IP growth rate using the available data.\n",
    "\n",
    "The dataset features columns that are coded for anonymity. To understand their actual macroeconomic interpretations, please consult the accompanying excel file named `macrodata_appendix.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to load the macroeconomic data. You don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "Macro1 = pd.read_csv(_DATA_DIR+'FredMD.csv')\n",
    "Macro1 = Macro1.drop(Macro1.columns[0], axis=1)\n",
    "X = Macro1.iloc[:, :-1]\n",
    "y = Macro1.iloc[:, -1]\n",
    "X['LagIP'] = y.shift(1)\n",
    "X = X.iloc[1:]\n",
    "y = y.iloc[1:]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA to do some preliminary analysis. Answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ How does the trend of IP growth look like? Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Draw a plot to compare different variables' correlation with IP growth rate. Which variables do you think are most useful? (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Model Selection & Parameter Tuning\n",
    "\n",
    "In this section, you are tasked with fitting four distinct models: Lasso Regression, Ridge Regression, Random Forest Regression, and Gradient Boosted Regression Trees. The benchmark model is a times series model: AR(1). Each model should be implemented using two different data partitioning strategies: the expanding window scheme and the rolling window scheme. Your goal is to evaluate and compare the out-of-sample prediction performance of these models.\n",
    "\n",
    "The expanding window scheme is a training and testing approach where the training dataset starts with a small subset of the data and incrementally incorporates more data points over time. This results in the training dataset growing to encompass a larger portion of the historical data, while the test set advances along the time axis, ensuring that the models are trained on increasingly comprehensive historical data.\n",
    "\n",
    "In contrast, the rolling window scheme involves advancing both the training and test sets forward in time by a fixed interval. This strategy ensures that the models are consistently trained and tested on consecutive datasets that are regularly updated with new data, maintaining a constant window size for both training and testing periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Rolling Window & Expanding Window "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Finish the following functions for building rolling window and expanding window iterators. The \"step\" parameter dictates the duration, in months, that each model remains valid, with a default value of 12 months to ensure that models derived from each rolling or expanding window remain effective for one year. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling window iterator\n",
    "def rolling_window_iterator(data, start_year = 1975, step = 12):\n",
    "    tscv_rolling = []\n",
    "    train_size = (start_year-1960)*12-2\n",
    "    for i in range(0,len(data) - train_size-step+1,step):\n",
    "        ##############################################################################\n",
    "        ### Define train and validation indices\n",
    "        ##############################################################################\n",
    "        train_index = data[i:(i+train_size)].index.values.astype(int)\n",
    "        ##############################################################################\n",
    "        tscv_rolling.append(train_index)\n",
    "    return tscv_rolling\n",
    "\n",
    "# generate expanding window iterator\n",
    "def expanding_window_iterator(data, start_year = 1975, step = 12):\n",
    "    tscv_expanding = []\n",
    "    train_size = (start_year-1960)*12-2\n",
    "    for i in range(0,len(data) - train_size - step+1,step):\n",
    "        ##############################################################################\n",
    "        ### TODO: Define train and validation indices\n",
    "        ##############################################################################\n",
    "        train_index = \n",
    "        ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "        tscv_expanding.append(train_index)\n",
    "    return tscv_expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up LASSO, Ridge, RF, & GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance(y, pred, family):\n",
    "    if family == 'gaussian':\n",
    "        return np.sum((y - pred)**2)\n",
    "    if family == 'binomial':\n",
    "        return -2 * np.sum(y * np.log(pred) + (1-y) * np.log(1-pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Finish the code for Lasso, Ridge, RF, and GBRT. Ensure your codes run smoothly with the functions provided below. (40 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_tuning(X_train, y_train, X_test, y_test, alphas):\n",
    "    \"\"\" Get series of dev0 and dev for given training and validation data and alphas\n",
    "    X_train: np.array of training covariates\n",
    "    y_train: np.array of training target\n",
    "    X_test: np.array of testing covariates\n",
    "    y_test: np.array of testing target\n",
    "    alphas: array of penalty strength\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################################################################\n",
    "    ### TODO: Construct Lasso\n",
    "    ##############################################################################\n",
    "    \n",
    "    Xscaler = \n",
    "    y_train = \n",
    "    yscaler = \n",
    "    \n",
    "    X_train_scaled = \n",
    "    y_train_scaled = \n",
    "    X_test_scaled = \n",
    "    \n",
    "    lasso = LassoCV(alphas=alphas, cv=3,random_state=0)\n",
    "    lasso.fit(X_train_scaled, y_train_scaled) \n",
    "    best_alpha = lasso.alpha_\n",
    "    \n",
    "    y_pred_scaled = \n",
    "    y_pred = \n",
    "    dev0 = \n",
    "    dev = \n",
    "    \n",
    "\n",
    "    ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "    return dev0, dev, best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_tuning(X_train, y_train, X_test, y_test, alphas):\n",
    "    \"\"\" Get series of dev0 and dev for given training and validation data and alphas\n",
    "    X_train: np.array of training covariates\n",
    "    y_train: np.array of training target\n",
    "    X_test: np.array of testing covariates\n",
    "    y_test: np.array of testing target\n",
    "    alphas: array of penalty strength\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    ### TODO: Construct Ridge\n",
    "    ##############################################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "    return dev0, dev, best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_tuning(X_train, y_train, X_test, y_test, param_grid):\n",
    " \n",
    "    \"\"\" Get series of dev0 and dev for given training and testing data and tuning parameters\n",
    "    X_train: np.array of training covariates\n",
    "    y_train: np.array of training target\n",
    "    X_test: np.array of testing covariates\n",
    "    y_test: np.array of testing target\n",
    "    param_grid: tuning parameters\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################################################################\n",
    "    ### TODO: Construct RF\n",
    "    ##############################################################################\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state = 0)\n",
    "    grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    grid_search_rf.fit(X_train, y_train.ravel())  \n",
    "    best_params = grid_search_rf.best_params_\n",
    "    best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "    y_pred =  \n",
    "    dev0 = \n",
    "    dev = \n",
    "\n",
    "     ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "    \n",
    "    return dev0, dev, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbrt_tuning(X_train, y_train, X_test, y_test, param_grid):\n",
    "\n",
    "    \"\"\" Get series of dev0 and dev for given training and testing data and tuning parameters\n",
    "    X_train: np.array of training covariates\n",
    "    y_train: np.array of training target\n",
    "    X_test: np.array of testing covariates\n",
    "    y_test: np.array of testing target\n",
    "    param_grid: tuning parameters\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    ### TODO: Construct GBRT\n",
    "    ############################################################################### \n",
    "\n",
    "    \n",
    "\n",
    "     ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "    \n",
    "    return dev0, dev, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Set Up Training and Prediction Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver1(X, y, mylist, method, params):\n",
    "    \n",
    "    \"\"\"Get OOS mse and r2 of different windows and best alphas\n",
    "    X: np.array of covariates\n",
    "    y: np.array of target\n",
    "    mylist: expanding list or rolling list\n",
    "    method: lasso or ridge\n",
    "    params: tuning parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    table_mse = pd.DataFrame(columns = range(len(mylist)))\n",
    "    table_r2 = pd.DataFrame(columns = range(len(mylist)))\n",
    "    table_alpha = pd.DataFrame(columns = range(len(mylist)))\n",
    "\n",
    "    for k in tqdm(range(len(mylist))):\n",
    "        train_idx = mylist[k]\n",
    "        X_train = X.iloc[train_idx,:]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test = X.iloc[(train_idx[-1]):(train_idx[-1]+12), :]\n",
    "        y_test = y.iloc[(train_idx[-1]):(train_idx[-1]+12)]\n",
    "        \n",
    "        if method == 'lasso':\n",
    "            dev0_ser, dev_ser, alpha = lasso_tuning(X_train, y_train, X_test, y_test, params)\n",
    "            table_mse.loc['Lasso_mse',k] = dev_ser/len(y_test)\n",
    "            table_r2.loc['Lasso_r2',k] = 1 - dev_ser/dev0_ser\n",
    "        elif method == 'ridge':\n",
    "            dev0_ser, dev_ser, alpha = ridge_tuning(X_train, y_train, X_test, y_test, params)\n",
    "            table_mse.loc['Ridge_mse',k] = dev_ser/len(y_test)\n",
    "            table_r2.loc['Ridge_r2',k] = 1 - dev_ser/dev0_ser\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "        table_alpha.loc['Alpha_best',k] = alpha\n",
    "    \n",
    "    \n",
    "    return table_mse,table_r2,table_alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver2(X, y, mylist, method, params):\n",
    "    \n",
    "    \"\"\"Get OOS mse and r2 of different windows.\n",
    "    X: np.array of covariates\n",
    "    y: np.array of target\n",
    "    mylist: expanding list or rolling list\n",
    "    method: rf or gbrt\n",
    "    params: tuning parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    table_mse = pd.DataFrame(columns = range(len(mylist)))\n",
    "    table_r2 = pd.DataFrame(columns = range(len(mylist)))\n",
    "    all_best_params = []\n",
    "\n",
    "    for k in tqdm(range(len(mylist))):\n",
    "        train_idx = mylist[k]\n",
    "        X_train = X.iloc[train_idx,:]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test = X.iloc[(train_idx[-1]):(train_idx[-1]+12), :]\n",
    "        y_test = y.iloc[(train_idx[-1]):(train_idx[-1]+12)]\n",
    "        \n",
    "        if method == 'rf':\n",
    "            dev0_ser, dev_ser, best_params = rf_tuning(X_train, y_train, X_test, y_test, params)\n",
    "            table_mse.loc['RF_mse',k] = dev_ser/len(y_test)\n",
    "            table_r2.loc['RF_r2',k] = 1 - dev_ser/dev0_ser\n",
    "        elif method == 'gbrt':\n",
    "            dev0_ser, dev_ser, best_params = gbrt_tuning(X_train, y_train, X_test, y_test, params)\n",
    "            table_mse.loc['GBRT_mse',k] = dev_ser/len(y_test)\n",
    "            table_r2.loc['GBRT_r2',k] = 1 - dev_ser/dev0_ser\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "        \n",
    "        all_best_params.append(best_params)\n",
    "   \n",
    "    return table_mse,table_r2,all_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: AR(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish the codes below for regressing the response variable `y` on its 1-time lag `y_{t-1}`. Return the mean squared error (MSE) of your baseline model. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARtrain(y, mylist):\n",
    "        \n",
    "    \"\"\"Get OOS mse and r2 of different windows.\n",
    "    y: np.array of target\n",
    "    mylist: expanding list or rolling list\n",
    "    \"\"\"\n",
    "    table_mse = pd.DataFrame(columns = range(len(mylist)))\n",
    "    \n",
    "    for k in tqdm(range(len(mylist))):\n",
    "        train_idx = mylist[k]\n",
    "        yinput_train = y[train_idx][:-1].values.reshape(-1,1)\n",
    "        yaim_train = y[train_idx][1:].values.reshape(-1,1)\n",
    "        yinput_test = y[(train_idx[-1]-1):(train_idx[-1]+11)].values.reshape(-1,1)\n",
    "        yaim_test = y[(train_idx[-1]):(train_idx[-1]+12)].values.reshape(-1,1)\n",
    "        model = LinearRegression().fit(yinput_train, yaim_train)\n",
    "\n",
    "    ##############################################################################\n",
    "    ### TODO: Finish AR Prediction\n",
    "    ############################################################################### \n",
    "       \n",
    "        y_pred_test = \n",
    "        yaim_test =         \n",
    "        mse_test =\n",
    "     \n",
    "    ##############################################################################\n",
    "        # END OF YOUR CODE  \n",
    "        table_mse.loc['MSE', k] = mse_test\n",
    "\n",
    "    return table_mse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR Training with Expanding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "expanding_list = expanding_window_iterator(y)\n",
    "# Run AR training procedure\n",
    "mse_ar_expanding = ARtrain(y, expanding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ar_expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR Training with Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "rolling_list = rolling_window_iterator(y)\n",
    "# Run AR training procedure\n",
    "mse_ar_rolling = ARtrain(y, rolling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ar_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ar_rolling.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction based on Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Training with Expanding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for Lasso (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "expanding_list = expanding_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of alphas\n",
    "    ##############################################################################\n",
    "    \n",
    "alphas =\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "expanding_lasso_table, expanding_l_r2_table,alpha_best_Lasso_expanding = solver1(X, y, expanding_list, method = 'lasso', params=alphas)\n",
    "\n",
    "# Report the best alphas. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "alpha_best_Lasso_expanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_lasso_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Training with Rolling Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for Lasso (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling window iterator\n",
    "rolling_list = rolling_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of alphas\n",
    "    ##############################################################################\n",
    "    \n",
    "alphas =\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "rolling_lasso_table, rolling_l_r2_table,alpha_best_Lasso_rolling = solver1(X, y, rolling_list, method = 'lasso', params=alphas)\n",
    "\n",
    "\n",
    "# Report the best alphas. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "alpha_best_Lasso_rolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_lasso_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction based on Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Training with Expanding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for Ridge (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "expanding_list = expanding_window_iterator(y)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of alphas\n",
    "    ##############################################################################\n",
    "    \n",
    "alphas = \n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "expanding_ridge_table, expanding_r_r2_table, alpha_best_Ridge_expanding = solver1(X, y, expanding_list, method = 'ridge', params=alphas)\n",
    "\n",
    "\n",
    "# Report the best alphas. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "alpha_best_Ridge_expanding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_ridge_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Training with Rolling Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for Ridge (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling window iterator\n",
    "rolling_list = rolling_window_iterator(y)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of alphas\n",
    "    ##############################################################################\n",
    "    \n",
    "alphas = \n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "rolling_ridge_table, rolling_r_r2_table,alpha_best_Ridge_rolling = solver1(X, y, rolling_list, method = 'ridge', params=alphas)\n",
    "\n",
    "\n",
    "# Report the best alphas. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "alpha_best_Ridge_rolling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_ridge_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Training with Expanding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for RF (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "expanding_list = expanding_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of parameters\n",
    "    ##############################################################################\n",
    "\n",
    "grid_rf = {\n",
    "    'max_depth': [],  \n",
    "    'max_features': []\n",
    "}\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "\n",
    "expanding_rf_mse_table,expanding_rf_r2_table,best_params_rf_expanding = solver2(X, y, expanding_list, method = 'rf', params=grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the best tuning parameters. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "best_params_rf_expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Training with Rolling Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for RF (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling window iterator\n",
    "rolling_list = rolling_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of parameters\n",
    "    ##############################################################################\n",
    "\n",
    "grid_rf = {\n",
    "    'max_depth': [],  \n",
    "    'max_features': []\n",
    "}\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "\n",
    "rolling_rf_mse_table,rolling_rf_r2_table,best_params_rf_rolling = solver2(X, y, rolling_list, method = 'rf', params=grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Report the best tuning parameters. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "best_params_rf_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBRT Training with Expanding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for GBRT (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate expanding window iterator\n",
    "expanding_list = expanding_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of parameters\n",
    "##############################################################################\n",
    "\n",
    "grid_gbrt = {\n",
    "    'max_depth': [], \n",
    "    'n_estimators': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "expanding_gbrt_mse_table,expanding_gbrt_r2_table,best_params_gbrt_expanding = solver2(X, y, expanding_list, method = 'gbrt', params=grid_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the best tuning parameters. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "best_params_gbrt_expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBRT Training with Rolling Winwdow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Select Tuning Parameter Range for GBRT (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rolling window iterator\n",
    "rolling_list = rolling_window_iterator(y)\n",
    "\n",
    "##############################################################################\n",
    "    ### TODO: Select a grid of parameters\n",
    "    ##############################################################################\n",
    "\n",
    "grid_gbrt = {\n",
    "    'max_depth': [], \n",
    "    'n_estimators': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    " ##############################################################################\n",
    "        # END OF YOUR CODE\n",
    "\n",
    "\n",
    "rolling_gbrt_mse_table,rolling_gbrt_r2_table,best_params_gbrt_rolling = solver2(X, y, rolling_list, method = 'gbrt', params=grid_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_gbrt_r2_table.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the best tuning parameters. Based on this, think if your tuning parameter range is reasonable.\n",
    "\n",
    "best_params_gbrt_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using the following code to compare your trained models with baseline model regarding MSE and R2. You don't need modify any code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mse_expanding = expanding_lasso_table.squeeze().tolist()\n",
    "r_mse_expanding = expanding_ridge_table.squeeze().tolist()\n",
    "rf_mse_expanding = expanding_rf_mse_table.squeeze().tolist()\n",
    "gbrt_mse_expanding = expanding_gbrt_mse_table.squeeze().tolist()\n",
    "\n",
    "OOS_MSE_expanding = pd.DataFrame({'Lasso':l_mse_expanding,'Ridge': r_mse_expanding,'RF': rf_mse_expanding, 'GBRT': gbrt_mse_expanding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r2_expanding = 1 - expanding_lasso_table.div(mse_ar_expanding.values)\n",
    "l_r2_expanding = l_r2_expanding.squeeze().tolist()\n",
    "\n",
    "r_r2_expanding = 1 - expanding_ridge_table.div(mse_ar_expanding.values)\n",
    "r_r2_expanding = r_r2_expanding.squeeze().tolist()\n",
    "\n",
    "rf_r2_expanding = 1 - expanding_rf_mse_table.div(mse_ar_expanding.values)\n",
    "rf_r2_expanding = rf_r2_expanding.squeeze().tolist()\n",
    "\n",
    "gbrt_r2_expanding = 1 - expanding_gbrt_mse_table.div(mse_ar_expanding.values)\n",
    "gbrt_r2_expanding = gbrt_r2_expanding.squeeze().tolist()\n",
    "\n",
    "OOS_R2_expanding = pd.DataFrame({'Lasso':l_r2_expanding, 'Ridge':r_r2_expanding, 'RF': rf_r2_expanding, 'GBRT': gbrt_r2_expanding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mse_rolling = rolling_lasso_table.squeeze().tolist()\n",
    "r_mse_rolling = rolling_ridge_table.squeeze().tolist()\n",
    "rf_mse_rolling = rolling_rf_mse_table.squeeze().tolist()\n",
    "gbrt_mse_rolling = rolling_gbrt_mse_table.squeeze().tolist()\n",
    "\n",
    "OOS_MSE_rolling = pd.DataFrame({'Lasso':l_mse_rolling,'Ridge': r_mse_rolling,'RF': rf_mse_rolling, 'GBRT': gbrt_mse_rolling})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r2_rolling = 1 - rolling_lasso_table.div(mse_ar_rolling.values)\n",
    "l_r2_rolling = l_r2_rolling.squeeze().tolist()\n",
    "\n",
    "r_r2_rolling = 1 - rolling_ridge_table.div(mse_ar_rolling.values)\n",
    "r_r2_rolling = r_r2_rolling.squeeze().tolist()\n",
    "\n",
    "rf_r2_rolling = 1 - rolling_rf_mse_table.div(mse_ar_rolling.values)\n",
    "rf_r2_rolling = rf_r2_rolling.squeeze().tolist()\n",
    "\n",
    "gbrt_r2_rolling = 1 - rolling_gbrt_mse_table.div(mse_ar_rolling.values)\n",
    "gbrt_r2_rolling = gbrt_r2_rolling.squeeze().tolist()\n",
    "\n",
    "OOS_R2_rolling = pd.DataFrame({'Lasso':l_r2_rolling, 'Ridge':r_r2_rolling, 'RF': rf_r2_rolling, 'GBRT': gbrt_r2_rolling})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sns.boxplot(data=OOS_R2_expanding )\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('R2')\n",
    "plt.title('OOS R2 expanding')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "sns.boxplot(data=OOS_MSE_expanding )\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('OOS MSE expanding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "sns.boxplot(data=OOS_R2_rolling )\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('R2')\n",
    "plt.title('OOS R2 rolling')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "sns.boxplot(data=OOS_MSE_rolling )\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('OOS MSE rolling')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Which model is best? Does your conclusion depend on rolling or expanding window design? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Is there any reason that supports your findings (10 points)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
